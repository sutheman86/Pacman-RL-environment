{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Pacman-world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. import all the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import gymnasium_env\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. test pacman-world environment\n",
    "* Without wrapper, without DQN. Pacman will move randomly\n",
    "> ***Note: DO NOT set `render_mode='human'`, or the kernel will crash (if you run this Notebook locally)***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "environment: gymnasium_env/PacmanGymEnv\n",
      "action space: 5\n",
      "observation space: (576, 448, 3)\n",
      "Step:  11 | Reward: -1.000 / -11.000 | Action: 0.000 | Info: {'lives': 3, 'total_score': 0}"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "env_name = \"gymnasium_env/PacmanGymEnv\"\n",
    "env = gym.make(env_name, speedup=5.0)\n",
    "env = env.unwrapped #減少限制\n",
    "\n",
    "print(\"environment:\", env_name)\n",
    "print(\"action space:\", env.action_space.n)\n",
    "# print(\"action:\", env.unwrapped.get_action_meanings())\n",
    "print(\"observation space:\", env.observation_space.shape)\n",
    "\n",
    "state = env.reset()\n",
    "step = 0\n",
    "total_reward=0\n",
    "while True:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, info = env.step(action)\n",
    "    step+=1\n",
    "    total_reward += reward\n",
    "    print('\\rStep: {:3d} | Reward: {:.3f} / {:.3f} | Action: {:.3f} | Info: {}'.format(step, reward, total_reward, action, info), end=\"\")\n",
    "    # if step%30==0:\n",
    "    #     plt.figure()\n",
    "    #     plt.imshow(obs)\n",
    "    #     plt.axis('off')  # 关闭坐标轴\n",
    "    # print(f\"state: {state[1]}\")\n",
    "    if terminated or step>10:\n",
    "        break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Define Wrapper\n",
    "* `PacmanEnvWrapper` will contain important information for DQN to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PacmanEnvWrapper(gym.Wrapper):\n",
    "    def __init__(self, env, k, img_size=(84,84)):\n",
    "        gym.Wrapper.__init__(self, env)\n",
    "        self.k = k\n",
    "        self.env = gym.make(env_name, speedup=5.0)\n",
    "        self.img_size = img_size\n",
    "        obs_shape = env.observation_space.shape\n",
    "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(k, img_size[0], img_size[1]), dtype=np.float32)\n",
    "\n",
    "    def _preprocess(self, state, th=0.182):\n",
    "        # TODO(Lab-1): Image processing.\n",
    "        state = np.array(Image.fromarray(state).resize(self.img_size,Image.BILINEAR))\n",
    "        state = state.astype(np.float32).mean(2) / 255.\n",
    "        state[state > th] = 1.0\n",
    "        state[state <= th] = 0.0\n",
    "\n",
    "        return state\n",
    "\n",
    "    def reset(self):\n",
    "        state = self.env.reset()\n",
    "\n",
    "        # 確認是否返回了tuple，並提取圖像\n",
    "        if isinstance(state, tuple):\n",
    "            state = state[0]\n",
    "\n",
    "        state = self._preprocess(state)\n",
    "        state = state[np.newaxis, ...].repeat(self.k, axis=0)  # 堆疊多幀\n",
    "        return state\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        state_next = []\n",
    "        info =[]\n",
    "        reward = 0\n",
    "        terminated = False\n",
    "        \n",
    "        for i in range(self.k):\n",
    "            if not terminated:\n",
    "                state_next_f, reward_f, terminated_f, info_f = self.env.step(action)\n",
    "                state_next_f = self._preprocess(state_next_f)\n",
    "                reward += reward_f\n",
    "                terminated = terminated_f\n",
    "                info.append(info_f)\n",
    "            state_next.append(state_next_f[np.newaxis, ...])\n",
    "        state_next = np.concatenate(state_next, 0)\n",
    "        return state_next, reward, terminated, info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Initialize Wrapper and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation space: (4, 84, 84)\n",
      "[[[1. 1. 1. ... 1. 1. 0.]\n",
      "  [1. 1. 1. ... 1. 1. 0.]\n",
      "  [1. 1. 1. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 1. 1. ... 0. 0. 0.]\n",
      "  [0. 1. 1. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 1. 1. ... 1. 1. 0.]\n",
      "  [1. 1. 1. ... 1. 1. 0.]\n",
      "  [1. 1. 1. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 1. 1. ... 0. 0. 0.]\n",
      "  [0. 1. 1. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 1. 1. ... 1. 1. 0.]\n",
      "  [1. 1. 1. ... 1. 1. 0.]\n",
      "  [1. 1. 1. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 1. 1. ... 0. 0. 0.]\n",
      "  [0. 1. 1. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 1. 1. ... 1. 1. 0.]\n",
      "  [1. 1. 1. ... 1. 1. 0.]\n",
      "  [1. 1. 1. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 1. 1. ... 0. 0. 0.]\n",
      "  [0. 1. 1. ... 0. 0. 0.]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1ec07ca42e0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Code\n",
    "env_pacman = PacmanEnvWrapper(env, k=4, img_size=(84,84))\n",
    "print(\"observation space:\", env_pacman.observation_space.shape)\n",
    "\n",
    "state = env_pacman.reset()\n",
    "action = env_pacman.action_space.sample()\n",
    "obs, reward, terminated, info = env_pacman.step(action)\n",
    "print(obs)\n",
    "plt.imshow(obs[0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Test `PacmanEnvWrapper`\n",
    "* Without DQN, test if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  11 | Reward: 149.000 / 517.000 | Action: 1.000 | Info: [{'lives': 3, 'total_score': 90}, {'lives': 3, 'total_score': 90}, {'lives': 3, 'total_score': 100}, {'lives': 3, 'total_score': 110}]"
     ]
    }
   ],
   "source": [
    "\n",
    "# env_name = \"gymnasium_env/PacmanGymEnv\"\n",
    "# env = gym.make(env_name, speedup=4.0)\n",
    "# env = env.unwrapped #減少限制\n",
    "\n",
    "# print(\"environment:\", env_name)\n",
    "# print(\"action space:\", env.action_space.n)\n",
    "# print(\"action:\", env.unwrapped.get_action_meanings())\n",
    "# print(\"observation space:\", env.observation_space.shape)\n",
    "pacman_env = PacmanEnvWrapper(env, k=4, img_size=(84,84))\n",
    "state = pacman_env.reset()\n",
    "step = 0\n",
    "total_reward = 0\n",
    "while True:\n",
    "    action = pacman_env.action_space.sample()\n",
    "    obs, reward, terminated, info = pacman_env.step(action)\n",
    "    step+=1\n",
    "    total_reward += reward\n",
    "    print('\\rStep: {:3d} | Reward: {:.3f} / {:.3f} | Action: {:.3f} | Info: {}'.format(step, reward, total_reward, action, info), end=\"\")\n",
    "    \n",
    "    # if step%40==0:\n",
    "    #     # print(30)\n",
    "    #     plt.figure()\n",
    "    #     plt.imshow(obs[0],cmap=\"gray\")\n",
    "    #     plt.axis('off')  # 关闭坐标轴\n",
    "    # print(f\"state: {state[1]}\")\n",
    "    if terminated or step>10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Output to GIF\n",
    "* remember to run it, it'll be used later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = os.getcwd()\n",
    "def save_gif(img_buffer, fname, gif_path=os.path.join(project_root, \"GIF\")):\n",
    "    if not os.path.exists(gif_path):\n",
    "        os.makedirs(gif_path)\n",
    "    img_buffer[0].save(os.path.join(gif_path, fname), save_all=True, append_images=img_buffer[1:], duration=3, loop=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Define QNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class QNet(nn.Module):\n",
    "    # TODO(Lab-4): Q-Network architecture.\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(QNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        conv_out_size = self._get_conv_out(input_shape)\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(conv_out_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_actions),\n",
    "        )\n",
    "\n",
    "    def _get_conv_out(self, shape):\n",
    "        o = self.conv(torch.zeros(1, *shape))\n",
    "        return int(np.prod(o.size()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out = self.conv(x)\n",
    "        out = self.fc(conv_out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DuelingQNet(nn.Module):\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(DuelingQNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        conv_out_size = self._get_conv_out(input_shape)\n",
    "\n",
    "        # Value stream\n",
    "        self.value_stream = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(conv_out_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1)  # Output a single value V(s)\n",
    "        )\n",
    "\n",
    "        # Advantage stream\n",
    "        self.advantage_stream = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(conv_out_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_actions)  # Output advantages A(s, a)\n",
    "        )\n",
    "\n",
    "    def _get_conv_out(self, shape):\n",
    "        o = self.conv(torch.zeros(1, *shape))\n",
    "        return int(np.prod(o.size()))\n",
    "\n",
    "    def forward(self, x):\n",
    "        conv_out = self.conv(x)\n",
    "        value = self.value_stream(conv_out)\n",
    "        advantage = self.advantage_stream(conv_out)\n",
    "\n",
    "        # Combine value and advantage to get Q-values\n",
    "        q_values = value + (advantage - advantage.mean(dim=1, keepdim=True))\n",
    "        return q_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Define DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepQNetwork():\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_actions,\n",
    "        input_shape,\n",
    "        qnet,\n",
    "        device,\n",
    "        learning_rate=2e-4,\n",
    "        reward_decay=0.99,\n",
    "        replace_target_iter=1000,\n",
    "        memory_size=10000,\n",
    "        batch_size=32,\n",
    "    ):\n",
    "        # initialize parameters\n",
    "        self.n_actions = n_actions\n",
    "        self.input_shape = input_shape\n",
    "        self.lr = learning_rate\n",
    "        self.gamma = reward_decay\n",
    "        self.replace_target_iter = replace_target_iter\n",
    "        self.memory_size = memory_size\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.learn_step_counter = 0\n",
    "        self.init_memory()\n",
    "\n",
    "        # Network\n",
    "        self.qnet_eval = qnet(self.input_shape, self.n_actions).to(self.device)\n",
    "        self.qnet_target = qnet(self.input_shape, self.n_actions).to(self.device)\n",
    "        self.qnet_target.eval()\n",
    "        self.optimizer = optim.RMSprop(self.qnet_eval.parameters(), lr=self.lr)\n",
    "\n",
    "    def choose_action(self, state, epsilon=0):\n",
    "        # 將狀態轉換為 FloatTensor 並增加 batch 維度\n",
    "        state = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
    "        actions_value = self.qnet_eval.forward(state)\n",
    "        if np.random.uniform() > epsilon:  # greedy\n",
    "            action = torch.max(actions_value, 1)[1].data.cpu().numpy()[0]\n",
    "        else:  # random\n",
    "            action = np.random.randint(0, self.n_actions)\n",
    "        return action\n",
    "\n",
    "    def learn(self):\n",
    "        # 替换目标网络参数\n",
    "        if self.learn_step_counter % self.replace_target_iter == 0:\n",
    "            self.qnet_target.load_state_dict(self.qnet_eval.state_dict())\n",
    "\n",
    "        # 随机采样经验池中的一个批次\n",
    "        if self.memory_counter > self.memory_size:\n",
    "            sample_index = np.random.choice(self.memory_size, size=self.batch_size)\n",
    "        else:\n",
    "            sample_index = np.random.choice(self.memory_counter, size=self.batch_size)\n",
    "\n",
    "        b_s = torch.FloatTensor(self.memory[\"s\"][sample_index]).to(self.device)\n",
    "        b_a = torch.LongTensor(self.memory[\"a\"][sample_index]).to(self.device)\n",
    "        b_r = torch.FloatTensor(self.memory[\"r\"][sample_index]).to(self.device)\n",
    "        b_s_ = torch.FloatTensor(self.memory[\"s_\"][sample_index]).to(self.device)\n",
    "        b_d = torch.FloatTensor(self.memory[\"done\"][sample_index]).to(self.device)\n",
    "\n",
    "        # DQN 和 DDQN 两种方式\n",
    "        q_curr_eval = self.qnet_eval(b_s).gather(1, b_a)\n",
    "        q_next_target = self.qnet_target(b_s_).detach()\n",
    "        q_next_eval = self.qnet_eval(b_s_).detach()\n",
    "        next_state_values = q_next_target.gather(1, q_next_eval.max(1)[1].unsqueeze(1))  # DDQN\n",
    "        q_curr_recur = b_r + (1 - b_d) * self.gamma * next_state_values\n",
    "\n",
    "        # 损失计算\n",
    "        self.loss = F.smooth_l1_loss(q_curr_eval, q_curr_recur)\n",
    "\n",
    "        # 反向传播和优化\n",
    "        self.optimizer.zero_grad()\n",
    "        self.loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.learn_step_counter += 1\n",
    "\n",
    "        return self.loss.detach().cpu().numpy()\n",
    "\n",
    "\n",
    "\n",
    "    def init_memory(self):\n",
    "        # 初始化经验池\n",
    "        self.memory = {\n",
    "            \"s\": np.zeros((self.memory_size, *self.input_shape)),\n",
    "            \"a\": np.zeros((self.memory_size, 1)),\n",
    "            \"r\": np.zeros((self.memory_size, 1)),\n",
    "            \"s_\": np.zeros((self.memory_size, *self.input_shape)),\n",
    "            \"done\": np.zeros((self.memory_size, 1)),\n",
    "        }\n",
    "\n",
    "    def store_transition(self, s, a, r, s_, d):\n",
    "        if not hasattr(self, 'memory_counter'):\n",
    "            self.memory_counter = 0\n",
    "        index = self.memory_counter % self.memory_size\n",
    "        self.memory[\"s\"][index] = s\n",
    "        self.memory[\"a\"][index] = np.array(a).reshape(-1, 1)\n",
    "        self.memory[\"r\"][index] = np.array(r).reshape(-1, 1)\n",
    "        self.memory[\"s_\"][index] = s_\n",
    "        self.memory[\"done\"][index] = np.array(d).reshape(-1, 1)\n",
    "        self.memory_counter += 1\n",
    "\n",
    "    def save_load_model(self, op, path=\"save\", fname=\"qnet.pt\"):\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "        file_path = os.path.join(path, fname)\n",
    "\n",
    "        if op == \"save\":\n",
    "            # 保存模型狀態、優化器狀態、學習步驟和經驗池計數\n",
    "            checkpoint = {\n",
    "                'qnet_eval_state_dict': self.qnet_eval.state_dict(),\n",
    "                'qnet_target_state_dict': self.qnet_target.state_dict(),\n",
    "                'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                'learn_step_counter': self.learn_step_counter,\n",
    "                'memory_counter': self.memory_counter,\n",
    "            }\n",
    "            torch.save(checkpoint, file_path)\n",
    "            print(f\"Model saved successfully at {file_path}\")\n",
    "\n",
    "        elif op == \"load\":\n",
    "            try:\n",
    "                # 加載模型狀態、優化器狀態、學習步驟和經驗池計數\n",
    "                checkpoint = torch.load(file_path, map_location=self.device)\n",
    "\n",
    "                # 檢查是否包含所有必需的鍵\n",
    "                required_keys = ['qnet_eval_state_dict', 'qnet_target_state_dict', 'optimizer_state_dict']\n",
    "                missing_keys = [key for key in required_keys if key not in checkpoint]\n",
    "\n",
    "                if missing_keys:\n",
    "                    raise KeyError(f\"Missing keys in checkpoint: {missing_keys}\")\n",
    "\n",
    "                # 加載各部分的狀態\n",
    "                self.qnet_eval.load_state_dict(checkpoint['qnet_eval_state_dict'])\n",
    "                self.qnet_target.load_state_dict(checkpoint['qnet_target_state_dict'])\n",
    "                self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "                # 選擇性地加載學習計數\n",
    "                self.learn_step_counter = checkpoint.get('learn_step_counter', 0)\n",
    "                self.memory_counter = checkpoint.get('memory_counter', 0)\n",
    "\n",
    "                print(\"Model loaded successfully from\", file_path)\n",
    "                return {'learn_step_counter': self.learn_step_counter, 'memory_counter': self.memory_counter}\n",
    "\n",
    "            except FileNotFoundError:\n",
    "                print(f\"No saved model found at {file_path}, starting fresh.\")\n",
    "            except KeyError as e:\n",
    "                print(f\"Error loading model: {e}\")\n",
    "\n",
    "        # 如果未成功加載模型或發生錯誤，返回初始狀態\n",
    "        return {'learn_step_counter': 0, 'memory_counter': 0}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Define Epsilon Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_compute(frame_id, epsilon_max=1, epsilon_min=0.05, epsilon_decay=100000):\n",
    "    return epsilon_min + (epsilon_max - epsilon_min) * np.exp(-frame_id / epsilon_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Graph of epsilon(0) to epsilon(400000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ec083fe680>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Code\n",
    "frame_ids = np.array(range(400000))\n",
    "epsilons = epsilon_compute(frame_ids)\n",
    "plt.plot(epsilons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Initialize DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuelingQNet(\n",
      "  (conv): Sequential(\n",
      "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
      "    (3): ReLU()\n",
      "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (value_stream): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=3136, out_features=512, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      "  (advantage_stream): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=3136, out_features=512, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Linear(in_features=512, out_features=5, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "stack_frames = 4\n",
    "img_size = (84,84)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "agent = DeepQNetwork(\n",
    "        n_actions = env.action_space.n,\n",
    "        input_shape = [stack_frames, *img_size],\n",
    "        # qnet = QNet,\n",
    "        qnet = DuelingQNet,\n",
    "        device = device,\n",
    "        learning_rate = 2e-5,\n",
    "        reward_decay = 0.95,\n",
    "        replace_target_iter = 1000,\n",
    "        memory_size = 10000,\n",
    "        batch_size = 32,)\n",
    "\n",
    "print(agent.qnet_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Define `Play()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gymnasium as gym\n",
    "import gymnasium_env\n",
    "def play(env, agent, stack_frames, img_size):\n",
    "    # Reset environment.\n",
    "    state = env.reset()\n",
    "    img_buffer = [Image.fromarray(state[0]*255)]\n",
    "\n",
    "    # Initialize information.\n",
    "    step = 0\n",
    "    total_reward = 0\n",
    "\n",
    "    # One episode.\n",
    "    while True:\n",
    "        # Select action.\n",
    "        action = agent.choose_action(state, 0)\n",
    "\n",
    "        # Get next stacked state.\n",
    "        state_next, reward, done, info = env.step(action)\n",
    "        if step % 2 == 0:\n",
    "            img_buffer.append(Image.fromarray(state_next[0]*255))\n",
    "\n",
    "        state = state_next.copy()\n",
    "        step += 1\n",
    "        total_reward += reward\n",
    "        print('\\rStep: {:3d} | Reward: {:.3f} / {:.3f} | Action: {:.3f} | Info: {}'.format(step, reward, total_reward, action, info[0]), end=\"\")\n",
    "\n",
    "        if done or step>1000:\n",
    "            print()\n",
    "            break\n",
    "\n",
    "    return img_buffer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Test play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Test play() function, *you don't need to run it if you did not change it*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 167 | Reward: -100.000 / 3699.000 | Action: 3.000 | Info: {'lives': 0, 'total_score': 1180}\n"
     ]
    }
   ],
   "source": [
    "env_pacman = PacmanEnvWrapper(env, k=4, img_size=(84,84))\n",
    "img_buffer = play(env_pacman, agent, stack_frames, img_size)\n",
    "save_gif(img_buffer, fname=\"test0.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Define `train()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(env, agent, stack_frames, img_size, save_path=\"save\", max_steps=1000000):\n",
    "    total_step = 0\n",
    "    episode = 0\n",
    "\n",
    "        # 嘗試加載模型和訓練狀態\n",
    "    try:\n",
    "        print(\"Loading model and training status...\")\n",
    "        status = agent.save_load_model(op=\"load\", path=save_path, fname=\"qnet.pt\")\n",
    "        total_step = status[\"learn_step_counter\"]\n",
    "        episode = status[\"memory_counter\"]\n",
    "        print(f\"Resuming training from total_step={total_step}, episode={episode}\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"No previous model found. Starting training from scratch.\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing key in checkpoint: {e}\")\n",
    "\n",
    "\n",
    "    while total_step <= max_steps:\n",
    "        # Reset environment.\n",
    "        state = env.reset()\n",
    "\n",
    "        # 如果 state 是 tuple，提取圖像\n",
    "        if isinstance(state, tuple):\n",
    "            state = state[0]\n",
    "\n",
    "        # Initialize information.\n",
    "        step = 0\n",
    "        total_reward = 0\n",
    "        loss = 0\n",
    "\n",
    "        # One episode.\n",
    "        while True:\n",
    "            # TODO(Lab-6): Select action.\n",
    "            epsilon = epsilon_compute(total_step)\n",
    "            action = agent.choose_action(state, epsilon)\n",
    "\n",
    "            # Get next observation.\n",
    "            obs, reward, terminated, info = env.step(action)\n",
    "\n",
    "            # 如果 obs 是 tuple，提取圖像\n",
    "            if isinstance(obs, tuple):\n",
    "                obs = obs[0]\n",
    "\n",
    "            # 判斷是否遊戲結束\n",
    "            done = terminated\n",
    "\n",
    "            # TODO(Lab-7): Train RL model.\n",
    "            # Store transition and learn.\n",
    "            agent.store_transition(state, action, reward, obs, done)\n",
    "            if total_step > 4 * agent.batch_size:\n",
    "                loss = agent.learn()\n",
    "\n",
    "            state = obs.copy()  # 更新狀態\n",
    "            step += 1\n",
    "            total_step += 1\n",
    "            total_reward += reward\n",
    "\n",
    "            # 確保 loss 為浮點數以便於打印\n",
    "            if total_step % 10 == 0 or done:\n",
    "                print('\\rEpisode: {:3d} | Step: {:3d} / {:3d} | Reward: {:.3f} / {:.3f} | Loss: {:.3f} | Epsilon: {:.3f}'\\\n",
    "                    .format(episode, step, total_step, reward, total_reward, loss, epsilon), end=\"\")\n",
    "\n",
    "            if total_step % 1000 == 0:\n",
    "                print(\"\\nSave Model ...\")\n",
    "                agent.save_load_model(\n",
    "                    op=\"save\",\n",
    "                    path=save_path,\n",
    "                    fname=\"qnet.pt\"\n",
    "                )\n",
    "                print(\"Generate GIF ...\")\n",
    "                img_buffer = play(env, agent, stack_frames, img_size)\n",
    "                save_gif(img_buffer, \"train_\" + str(total_step).zfill(6) + \".gif\")\n",
    "                print(\"Done !!\")\n",
    "\n",
    "            if done or step > 1000:\n",
    "                episode += 1\n",
    "                print()\n",
    "                break\n",
    "\n",
    "        if total_step > max_steps:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 600step/min on Colab (with T4 GPU), 400step/min on RTX3070 laptop. Pretty slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model and training status...\n",
      "Model loaded successfully from c:\\Users\\howar\\Code_on_win\\Gym\\latest\\Pacman-RL-environment\\save\\qnet.pt\n",
      "Resuming training from total_step=1205, episode=1463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howar\\AppData\\Local\\Temp\\ipykernel_29384\\2425402526.py:120: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(file_path, map_location=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1463 | Step:  98 / 1303 | Reward: -102.000 / 3146.000 | Loss: 6.361 | Epsilon: 0.988\n",
      "Episode: 1464 | Step:  71 / 1374 | Reward: -100.000 / 1564.000 | Loss: 0.240 | Epsilon: 0.987\n",
      "Episode: 1465 | Step: 106 / 1480 | Reward: -100.000 / 3585.000 | Loss: 1.530 | Epsilon: 0.986\n",
      "Episode: 1466 | Step:  82 / 1562 | Reward: -100.000 / 1877.000 | Loss: 0.275 | Epsilon: 0.985\n",
      "Episode: 1467 | Step:  69 / 1631 | Reward: -102.000 / 346.000 | Loss: 10.872 | Epsilon: 0.985\n",
      "Episode: 1468 | Step: 105 / 1736 | Reward: -100.000 / 2458.000 | Loss: 9.510 | Epsilon: 0.984\n",
      "Episode: 1469 | Step:  96 / 1832 | Reward: -52.000 / 3011.000 | Loss: 24.047 | Epsilon: 0.983\n",
      "Episode: 1470 | Step: 112 / 1944 | Reward: -100.000 / 2073.000 | Loss: 23.352 | Epsilon: 0.982\n",
      "Episode: 1471 | Step:  56 / 2000 | Reward: -4.000 / -14.000 | Loss: 14.246 | Epsilon: 0.98181\n",
      "Save Model ...\n",
      "Model saved successfully at c:\\Users\\howar\\Code_on_win\\Gym\\latest\\Pacman-RL-environment\\save\\qnet.pt\n",
      "Generate GIF ...\n",
      "Step: 134 | Reward: -101.000 / 2953.000 | Action: 4.000 | Info: {'lives': 1, 'total_score': 970}\n",
      "Done !!\n",
      "Episode: 1471 | Step:  57 / 2001 | Reward: -1.000 / -15.000 | Loss: 10.142 | Epsilon: 0.981\n",
      "Episode: 1472 | Step:  54 / 2055 | Reward: -100.000 / 612.000 | Loss: 14.389 | Epsilon: 0.981\n",
      "Episode: 1473 | Step: 141 / 2196 | Reward: -103.000 / 3443.000 | Loss: 15.732 | Epsilon: 0.979\n",
      "Episode: 1474 | Step:  47 / 2243 | Reward: -102.000 / 587.000 | Loss: 10.246 | Epsilon: 0.979\n",
      "Episode: 1475 | Step:  82 / 2325 | Reward: -101.000 / 2386.000 | Loss: 23.215 | Epsilon: 0.978\n",
      "Episode: 1476 | Step:  45 / 2370 | Reward: -102.000 / 187.000 | Loss: 23.534 | Epsilon: 0.978\n",
      "Episode: 1477 | Step:  84 / 2454 | Reward: -100.000 / 1308.000 | Loss: 12.769 | Epsilon: 0.977\n",
      "Episode: 1478 | Step: 119 / 2573 | Reward: -103.000 / 2807.000 | Loss: 26.420 | Epsilon: 0.976\n",
      "Episode: 1479 | Step:  79 / 2652 | Reward: -100.000 / 2449.000 | Loss: 15.715 | Epsilon: 0.975\n",
      "Episode: 1480 | Step:  75 / 2727 | Reward: -103.000 / 1494.000 | Loss: 26.665 | Epsilon: 0.974\n",
      "Episode: 1481 | Step: 114 / 2841 | Reward: -102.000 / 2216.000 | Loss: 7.643 | Epsilon: 0.973\n",
      "Episode: 1482 | Step:  71 / 2912 | Reward: -100.000 / 1717.000 | Loss: 8.119 | Epsilon: 0.9733\n",
      "Episode: 1483 | Step:  48 / 2960 | Reward: -102.000 / 328.000 | Loss: 35.645 | Epsilon: 0.972\n",
      "Episode: 1484 | Step:  40 / 3000 | Reward: 98.000 / 812.000 | Loss: 8.624 | Epsilon: 0.97222\n",
      "Save Model ...\n",
      "Model saved successfully at c:\\Users\\howar\\Code_on_win\\Gym\\latest\\Pacman-RL-environment\\save\\qnet.pt\n",
      "Generate GIF ...\n",
      "Step:  62 | Reward: -101.000 / 324.000 | Action: 3.000 | Info: {'lives': 1, 'total_score': 170}\n",
      "Done !!\n",
      "Episode: 1484 | Step:  41 / 3001 | Reward: -1.000 / 811.000 | Loss: 16.078 | Epsilon: 0.972\n",
      "Episode: 1485 | Step:  86 / 3087 | Reward: -102.000 / 1818.000 | Loss: 26.517 | Epsilon: 0.971\n",
      "Episode: 1486 | Step:  54 / 3141 | Reward: -100.000 / 1377.000 | Loss: 40.711 | Epsilon: 0.971\n",
      "Episode: 1487 | Step:  98 / 3239 | Reward: -101.000 / 3240.000 | Loss: 18.380 | Epsilon: 0.970\n",
      "Episode: 1488 | Step:  83 / 3322 | Reward: -102.000 / 1575.000 | Loss: 19.455 | Epsilon: 0.969\n",
      "Episode: 1489 | Step:  84 / 3406 | Reward: -100.000 / 1675.000 | Loss: 30.011 | Epsilon: 0.968\n",
      "Episode: 1490 | Step:  55 / 3461 | Reward: -103.000 / 1166.000 | Loss: 20.099 | Epsilon: 0.968\n",
      "Episode: 1491 | Step:  43 / 3504 | Reward: -103.000 / 1265.000 | Loss: 17.664 | Epsilon: 0.967\n",
      "Episode: 1492 | Step:  55 / 3559 | Reward: -100.000 / 965.000 | Loss: 27.894 | Epsilon: 0.967\n",
      "Episode: 1493 | Step:  51 / 3610 | Reward: -100.000 / 114.000 | Loss: 11.627 | Epsilon: 0.966\n",
      "Episode: 1494 | Step:  81 / 3691 | Reward: -102.000 / 2491.000 | Loss: 13.176 | Epsilon: 0.966\n",
      "Episode: 1495 | Step: 109 / 3800 | Reward: -101.000 / 3665.000 | Loss: 9.967 | Epsilon: 0.9655\n",
      "Episode: 1496 | Step:  66 / 3866 | Reward: 50.000 / 1020.000 | Loss: 30.231 | Epsilon: 0.964\n",
      "Episode: 1497 | Step: 112 / 3978 | Reward: -102.000 / 2897.000 | Loss: 19.066 | Epsilon: 0.963\n",
      "Episode: 1498 | Step:  22 / 4000 | Reward: 98.000 / 1289.000 | Loss: 18.902 | Epsilon: 0.963\n",
      "Save Model ...\n",
      "Model saved successfully at c:\\Users\\howar\\Code_on_win\\Gym\\latest\\Pacman-RL-environment\\save\\qnet.pt\n",
      "Generate GIF ...\n",
      "Step:  90 | Reward: -100.000 / 3028.000 | Action: 1.000 | Info: {'lives': 0, 'total_score': 760}\n",
      "Done !!\n",
      "Episode: 1498 | Step:  23 / 4001 | Reward: -1.000 / 1288.000 | Loss: 33.726 | Epsilon: 0.963\n",
      "Episode: 1499 | Step: 105 / 4106 | Reward: -100.000 / 2927.000 | Loss: 24.445 | Epsilon: 0.962\n",
      "Episode: 1500 | Step:  71 / 4177 | Reward: -100.000 / 1370.000 | Loss: 40.979 | Epsilon: 0.961\n",
      "Episode: 1501 | Step:  51 / 4228 | Reward: -100.000 / 930.000 | Loss: 15.524 | Epsilon: 0.961\n",
      "Episode: 1502 | Step:  67 / 4295 | Reward: -51.000 / 1476.000 | Loss: 20.132 | Epsilon: 0.960\n",
      "Episode: 1503 | Step:  74 / 4369 | Reward: -102.000 / 1855.000 | Loss: 25.593 | Epsilon: 0.959\n",
      "Episode: 1504 | Step: 111 / 4480 | Reward: -103.000 / 2951.000 | Loss: 27.085 | Epsilon: 0.958\n",
      "Episode: 1505 | Step: 109 / 4589 | Reward: -102.000 / 2950.000 | Loss: 35.931 | Epsilon: 0.957\n",
      "Episode: 1506 | Step: 103 / 4692 | Reward: -101.000 / 2465.000 | Loss: 19.296 | Epsilon: 0.956\n",
      "Episode: 1507 | Step: 110 / 4802 | Reward: -100.000 / 4335.000 | Loss: 24.834 | Epsilon: 0.955\n",
      "Episode: 1508 | Step: 132 / 4934 | Reward: -103.000 / 3581.000 | Loss: 16.928 | Epsilon: 0.954\n",
      "Episode: 1509 | Step:  66 / 5000 | Reward: -4.000 / 2860.000 | Loss: 23.290 | Epsilon: 0.9544\n",
      "Save Model ...\n",
      "Model saved successfully at c:\\Users\\howar\\Code_on_win\\Gym\\latest\\Pacman-RL-environment\\save\\qnet.pt\n",
      "Generate GIF ...\n",
      "Step:  86 | Reward: -101.000 / 3084.000 | Action: 0.000 | Info: {'lives': 1, 'total_score': 730}\n",
      "Done !!\n",
      "Episode: 1509 | Step:  67 / 5001 | Reward: -1.000 / 2859.000 | Loss: 51.290 | Epsilon: 0.954\n",
      "Episode: 1510 | Step:  80 / 5081 | Reward: -103.000 / 1637.000 | Loss: 28.592 | Epsilon: 0.953\n",
      "Episode: 1511 | Step:  50 / 5131 | Reward: -100.000 / 1189.000 | Loss: 30.784 | Epsilon: 0.952\n",
      "Episode: 1512 | Step:  81 / 5212 | Reward: -100.000 / 2036.000 | Loss: 16.724 | Epsilon: 0.952\n",
      "Episode: 1513 | Step: 109 / 5321 | Reward: -103.000 / 3000.000 | Loss: 23.258 | Epsilon: 0.951\n",
      "Episode: 1514 | Step:  83 / 5404 | Reward: -100.000 / 1780.000 | Loss: 15.787 | Epsilon: 0.950\n",
      "Episode: 1515 | Step:  69 / 5473 | Reward: -100.000 / 1266.000 | Loss: 28.684 | Epsilon: 0.949\n",
      "Episode: 1516 | Step:  50 / 5523 | Reward: -103.000 / 625.000 | Loss: 39.587 | Epsilon: 0.949\n",
      "Episode: 1517 | Step:  93 / 5616 | Reward: -101.000 / 2556.000 | Loss: 35.093 | Epsilon: 0.948\n",
      "Episode: 1518 | Step:  70 / 5686 | Reward: -100.000 / 751.000 | Loss: 38.305 | Epsilon: 0.947\n",
      "Episode: 1519 | Step:  85 / 5771 | Reward: -100.000 / 2273.000 | Loss: 22.681 | Epsilon: 0.947\n",
      "Episode: 1520 | Step: 112 / 5883 | Reward: -2.000 / 3201.000 | Loss: 30.936 | Epsilon: 0.94666\n",
      "Episode: 1521 | Step: 105 / 5988 | Reward: -103.000 / 2455.000 | Loss: 24.653 | Epsilon: 0.945\n",
      "Episode: 1522 | Step:  12 / 6000 | Reward: 47.000 / 258.000 | Loss: 19.764 | Epsilon: 0.945\n",
      "Save Model ...\n",
      "Model saved successfully at c:\\Users\\howar\\Code_on_win\\Gym\\latest\\Pacman-RL-environment\\save\\qnet.pt\n",
      "Generate GIF ...\n",
      "Step:  56 | Reward: -101.000 / 93.000 | Action: 4.000 | Info: {'lives': 1, 'total_score': 120}\n",
      "Done !!\n",
      "Episode: 1522 | Step:  13 / 6001 | Reward: -1.000 / 257.000 | Loss: 57.822 | Epsilon: 0.945\n",
      "Episode: 1523 | Step: 135 / 6136 | Reward: -103.000 / 3926.000 | Loss: 50.724 | Epsilon: 0.943\n",
      "Episode: 1524 | Step:  49 / 6185 | Reward: -101.000 / 274.000 | Loss: 23.146 | Epsilon: 0.943\n",
      "Episode: 1525 | Step:  74 / 6259 | Reward: -100.000 / 1613.000 | Loss: 34.531 | Epsilon: 0.942\n",
      "Episode: 1526 | Step:  82 / 6341 | Reward: -101.000 / 1723.000 | Loss: 48.271 | Epsilon: 0.942\n",
      "Episode: 1527 | Step:  71 / 6412 | Reward: -103.000 / 1917.000 | Loss: 17.421 | Epsilon: 0.941\n",
      "Episode: 1528 | Step: 111 / 6523 | Reward: -101.000 / 2739.000 | Loss: 27.536 | Epsilon: 0.940\n",
      "Episode: 1529 | Step:  51 / 6574 | Reward: -100.000 / 725.000 | Loss: 24.752 | Epsilon: 0.940\n",
      "Episode: 1530 | Step:  81 / 6655 | Reward: -100.000 / 2085.000 | Loss: 39.473 | Epsilon: 0.939\n",
      "Episode: 1531 | Step: 168 / 6823 | Reward: -100.000 / 2469.000 | Loss: 20.421 | Epsilon: 0.937\n",
      "Episode: 1532 | Step: 101 / 6924 | Reward: -100.000 / 2525.000 | Loss: 38.779 | Epsilon: 0.936\n",
      "Episode: 1533 | Step:  44 / 6968 | Reward: -102.000 / 395.000 | Loss: 27.847 | Epsilon: 0.936\n",
      "Episode: 1534 | Step:  32 / 7000 | Reward: -4.000 / 1150.000 | Loss: 38.188 | Epsilon: 0.93636\n",
      "Save Model ...\n",
      "Model saved successfully at c:\\Users\\howar\\Code_on_win\\Gym\\latest\\Pacman-RL-environment\\save\\qnet.pt\n",
      "Generate GIF ...\n",
      "Step:  63 | Reward: -100.000 / 1137.000 | Action: 3.000 | Info: {'lives': 0, 'total_score': 330}\n",
      "Done !!\n",
      "Episode: 1534 | Step:  33 / 7001 | Reward: -1.000 / 1149.000 | Loss: 45.866 | Epsilon: 0.936\n",
      "Episode: 1535 | Step:  97 / 7098 | Reward: -101.000 / 3254.000 | Loss: 43.963 | Epsilon: 0.935\n",
      "Episode: 1536 | Step: 132 / 7230 | Reward: -52.000 / 2908.000 | Loss: 19.049 | Epsilon: 0.934\n",
      "Episode: 1537 | Step:  48 / 7278 | Reward: -103.000 / 531.000 | Loss: 34.759 | Epsilon: 0.933\n",
      "Episode: 1538 | Step:  65 / 7343 | Reward: -101.000 / 1689.000 | Loss: 37.375 | Epsilon: 0.933\n",
      "Episode: 1539 | Step:  69 / 7412 | Reward: -100.000 / 1623.000 | Loss: 34.711 | Epsilon: 0.932\n",
      "Episode: 1540 | Step:  47 / 7459 | Reward: -100.000 / 1609.000 | Loss: 36.758 | Epsilon: 0.932\n",
      "Episode: 1541 | Step: 109 / 7568 | Reward: -100.000 / 2605.000 | Loss: 32.276 | Epsilon: 0.931\n",
      "Episode: 1542 | Step:  77 / 7645 | Reward: -100.000 / 2713.000 | Loss: 17.031 | Epsilon: 0.930\n",
      "Episode: 1543 | Step: 106 / 7751 | Reward: -101.000 / 3839.000 | Loss: 46.371 | Epsilon: 0.929\n",
      "Episode: 1544 | Step:  51 / 7802 | Reward: -101.000 / 417.000 | Loss: 48.090 | Epsilon: 0.929\n",
      "Episode: 1545 | Step:  51 / 7853 | Reward: -100.000 / 267.000 | Loss: 30.743 | Epsilon: 0.928\n",
      "Episode: 1546 | Step:  67 / 7920 | Reward: -100.000 / 1121.000 | Loss: 21.179 | Epsilon: 0.928\n",
      "Episode: 1547 | Step:  80 / 8000 | Reward: -4.000 / 1379.000 | Loss: 23.712 | Epsilon: 0.92727\n",
      "Save Model ...\n",
      "Model saved successfully at c:\\Users\\howar\\Code_on_win\\Gym\\latest\\Pacman-RL-environment\\save\\qnet.pt\n",
      "Generate GIF ...\n",
      "Step:  56 | Reward: -100.000 / 349.000 | Action: 3.000 | Info: {'lives': 0, 'total_score': 170}\n",
      "Done !!\n",
      "Episode: 1547 | Step:  81 / 8001 | Reward: -1.000 / 1378.000 | Loss: 27.530 | Epsilon: 0.927\n",
      "Episode: 1548 | Step: 103 / 8104 | Reward: -101.000 / 3026.000 | Loss: 34.434 | Epsilon: 0.926\n",
      "Episode: 1549 | Step:  49 / 8153 | Reward: -103.000 / 1547.000 | Loss: 40.865 | Epsilon: 0.926\n",
      "Episode: 1550 | Step:  96 / 8249 | Reward: -100.000 / 3269.000 | Loss: 50.760 | Epsilon: 0.925\n",
      "Episode: 1551 | Step:  66 / 8315 | Reward: -103.000 / 1377.000 | Loss: 38.580 | Epsilon: 0.924\n",
      "Episode: 1552 | Step:  85 / 8400 | Reward: -100.000 / 2273.000 | Loss: 38.853 | Epsilon: 0.923\n",
      "Episode: 1553 | Step: 209 / 8609 | Reward: -100.000 / 2511.000 | Loss: 42.211 | Epsilon: 0.922\n",
      "Episode: 1554 | Step: 131 / 8740 | Reward: -100.000 / 3700.000 | Loss: 27.461 | Epsilon: 0.921\n",
      "Episode: 1555 | Step: 104 / 8844 | Reward: -100.000 / 2615.000 | Loss: 22.784 | Epsilon: 0.920\n",
      "Episode: 1556 | Step:  99 / 8943 | Reward: -101.000 / 2848.000 | Loss: 29.509 | Epsilon: 0.919\n",
      "Episode: 1557 | Step:  57 / 9000 | Reward: -4.000 / 1873.000 | Loss: 25.212 | Epsilon: 0.9188\n",
      "Save Model ...\n",
      "Model saved successfully at c:\\Users\\howar\\Code_on_win\\Gym\\latest\\Pacman-RL-environment\\save\\qnet.pt\n",
      "Generate GIF ...\n",
      "Step:  58 | Reward: -101.000 / 1207.000 | Action: 0.000 | Info: {'lives': 1, 'total_score': 340}\n",
      "Done !!\n",
      "Episode: 1557 | Step:  58 / 9001 | Reward: -1.000 / 1872.000 | Loss: 53.197 | Epsilon: 0.918\n",
      "Episode: 1558 | Step: 142 / 9143 | Reward: -50.000 / 3992.000 | Loss: 48.939 | Epsilon: 0.9177\n",
      "Episode: 1559 | Step:  49 / 9192 | Reward: -103.000 / 425.000 | Loss: 27.498 | Epsilon: 0.917\n",
      "Episode: 1560 | Step:  90 / 9282 | Reward: -50.000 / 2456.000 | Loss: 38.227 | Epsilon: 0.916\n",
      "Episode: 1561 | Step:  71 / 9353 | Reward: -100.000 / 2389.000 | Loss: 61.700 | Epsilon: 0.915\n",
      "Episode: 1562 | Step:  73 / 9426 | Reward: -103.000 / 1502.000 | Loss: 85.445 | Epsilon: 0.915\n",
      "Episode: 1563 | Step:  48 / 9474 | Reward: -100.000 / 839.000 | Loss: 49.078 | Epsilon: 0.914\n",
      "Episode: 1564 | Step:  71 / 9545 | Reward: -50.000 / 1869.000 | Loss: 44.175 | Epsilon: 0.9144\n",
      "Episode: 1565 | Step: 120 / 9665 | Reward: -50.000 / 2917.000 | Loss: 52.193 | Epsilon: 0.9123\n",
      "Episode: 1566 | Step: 128 / 9793 | Reward: -100.000 / 3906.000 | Loss: 55.894 | Epsilon: 0.911\n",
      "Episode: 1567 | Step:  66 / 9859 | Reward: -103.000 / 2152.000 | Loss: 28.095 | Epsilon: 0.911\n",
      "Episode: 1568 | Step:  72 / 9931 | Reward: -103.000 / 1097.000 | Loss: 31.802 | Epsilon: 0.910\n",
      "Episode: 1569 | Step:  63 / 9994 | Reward: -50.000 / 1595.000 | Loss: 47.515 | Epsilon: 0.910\n",
      "Episode: 1570 | Step:   6 / 10000 | Reward: -4.000 / -24.000 | Loss: 20.066 | Epsilon: 0.910\n",
      "Save Model ...\n",
      "Model saved successfully at c:\\Users\\howar\\Code_on_win\\Gym\\latest\\Pacman-RL-environment\\save\\qnet.pt\n",
      "Generate GIF ...\n",
      "Step:  96 | Reward: -102.000 / 1829.000 | Action: 3.000 | Info: {'lives': 1, 'total_score': 530}\n",
      "Done !!\n",
      "Episode: 1570 | Step:   7 / 10001 | Reward: -1.000 / -25.000 | Loss: 53.317 | Epsilon: 0.910\n",
      "Episode: 1571 | Step:  74 / 10075 | Reward: -100.000 / 2173.000 | Loss: 52.867 | Epsilon: 0.909\n",
      "Episode: 1572 | Step: 131 / 10206 | Reward: -100.000 / 1946.000 | Loss: 55.066 | Epsilon: 0.908\n",
      "Episode: 1573 | Step:  34 / 10240 | Reward: -4.000 / 1139.000 | Loss: 40.348 | Epsilon: 0.908"
     ]
    }
   ],
   "source": [
    "env_pacman = PacmanEnvWrapper(env, k=4, img_size=(84,84))\n",
    "train(env_pacman, agent, stack_frames, img_size, save_path=os.path.join(project_root, \"save\"), max_steps=600000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\howar\\AppData\\Local\\Temp\\ipykernel_29384\\2425402526.py:120: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(file_path, map_location=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from c:\\Users\\howar\\Code_on_win\\Gym\\latest\\Pacman-RL-environment\\save\\qnet.pt\n",
      "Step:  49 | Reward: -102.000 / 171.000 | Action: 0.000 | Info: {'lives': 1, 'total_score': 130}\n"
     ]
    }
   ],
   "source": [
    "agent.save_load_model(op=\"load\", path=os.path.join(project_root, \"save\"), fname=\"qnet.pt\")\n",
    "env_pacman = PacmanEnvWrapper(env, k=4, img_size=(84,84))\n",
    "img_buffer = play(env_pacman, agent, stack_frames, img_size)\n",
    "save_gif(img_buffer, \"eval.gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Codes\n",
    "* Would probably be useful later or really just junks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.\n",
    "* This is to test `PacmanGymEnv` could run by itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import gymnasium_env\n",
    "# import gymnasium\n",
    "# import warnings\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# import os\n",
    "\n",
    "# # 設定無視窗模式\n",
    "# os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "\n",
    "# # 忽略 DeprecationWarning\n",
    "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "# # 初始化環境\n",
    "# env = gymnasium.make('gymnasium_env/PacmanGymEnv', speedup=4.0)\n",
    "# obs, info = env.reset()\n",
    "# env_unwrapped = env.unwrapped   \n",
    "\n",
    "# # 用來保存每一幀的圖像\n",
    "# frames = []\n",
    "\n",
    "# # 設定最多 1000 步\n",
    "# for step in range(1000):\n",
    "#     action = env.action_space.sample()  # 隨機取樣一個動作\n",
    "#     obs, reward, done, info = env.step(action)\n",
    "    \n",
    "    \n",
    "#     # 確保返回值非空並且是 numpy array 格式\n",
    "#     if obs is not None and isinstance(obs, np.ndarray):\n",
    "#         img = Image.fromarray(obs)  # 轉換為 PIL 圖像格式\n",
    "#         frames.append(img)  # 添加幀到 frames 列表中\n",
    "#     else:\n",
    "#         print(\"Render did not return a valid image.\")\n",
    "    \n",
    "#     print(f\"Step: {step + 1}, Action: {action}, Reward: {reward}, Info: {info}, Done: {done}\")\n",
    "\n",
    "#     # 檢查是否回合結束\n",
    "#     if done:\n",
    "#         print(\"Episode finished!\")\n",
    "#         break\n",
    "\n",
    "# # 關閉環境\n",
    "# env.close()\n",
    "\n",
    "# # 保存為 GIF\n",
    "# output_path = \"../Gif/pacman_game.gif\"\n",
    "# frames[0].save(output_path, save_all=True, append_images=frames[1:], duration=100, loop=1)\n",
    "# print(f\"GIF saved as {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5.\n",
    "* Old implementation of `play()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def play(env, agent, stack_frames, img_size):\n",
    "#     #os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "#     # Reset environment.\n",
    "#     state = env.reset()\n",
    "\n",
    "#     # 如果state是tuple，提取第一個元素作為圖像\n",
    "#     if isinstance(state, tuple):\n",
    "#         state = state[0]\n",
    "\n",
    "#     # state形狀應該是 (k, 84, 84)，所以不再提取單幀\n",
    "#     # 確保數據類型為uint8，並去除不必要的維度\n",
    "#     state = (state * 255).astype(np.uint8)\n",
    "\n",
    "#     # 初始化圖像緩衝區\n",
    "#     img_buffer = [Image.fromarray(state[0])]  # 顯示第一幀\n",
    "\n",
    "#     # Initialize information.\n",
    "#     step = 0\n",
    "#     total_reward = 0\n",
    "\n",
    "#     # One episode.\n",
    "#     while True:\n",
    "#         # Select action.\n",
    "#         action = agent.choose_action(state, 0)\n",
    "\n",
    "#         # Get next stacked state.\n",
    "#         state_next, reward, terminated, info = env.step(action)\n",
    "\n",
    "#         # 如果 state_next 是 tuple，提取圖像\n",
    "#         if isinstance(state_next, tuple):\n",
    "#             state_next = state_next[0]\n",
    "\n",
    "#         # 不再提取單幀，直接使用多幀數據\n",
    "#         state_next = (state_next * 255).astype(np.uint8)\n",
    "\n",
    "#         # 每兩步存儲一幀圖像\n",
    "#         if step % 2 == 0:\n",
    "#             img_buffer.append(Image.fromarray(state_next[0]))  # 顯示第一幀\n",
    "\n",
    "#         state = state_next.copy()  # 更新狀態\n",
    "#         step += 1\n",
    "#         total_reward += reward\n",
    "#         print('\\rStep: {:3d} | Reward: {:.3f} / {:.3f} | Action: {:.3f} | Info: {}'.format(step, reward, total_reward, action, info[0]), end=\"\")\n",
    "\n",
    "\n",
    "#         # 檢查遊戲是否結束或步數超過2000\n",
    "#         if terminated  or step > 400:\n",
    "#             print()\n",
    "#             break\n",
    "\n",
    "#     return img_buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5.2\n",
    "* Old implementation of learn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9.\n",
    "* This piece of code attempted to load model but failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # 嘗試加載模型和訓練狀態\n",
    "    # try:\n",
    "    #     print(\"Loading model and training status...\")\n",
    "    #     status = agent.save_load_model(op=\"load\", path=save_path, fname=\"qnet.pt\")\n",
    "    #     total_step = status[\"learn_step_counter\"]\n",
    "    #     episode = status[\"memory_counter\"]\n",
    "    #     print(f\"Resuming training from total_step={total_step}, episode={episode}\")\n",
    "    # except FileNotFoundError:\n",
    "    #     print(\"No previous model found. Starting training from scratch.\")\n",
    "    # except KeyError as e:\n",
    "    #     print(f\"Missing key in checkpoint: {e}\")\n",
    "\n",
    "    # try:\n",
    "    #     print(\"Loading model and training status...\")\n",
    "    #     status = agent.save_load_model(op=\"load\", path=save_path, fname=\"qnet.pt\")\n",
    "    #     total_step = status.get(\"total_step\", 0)\n",
    "    #     episode = status.get(\"episode\", 0)\n",
    "    #     print(f\"Resuming training from total_step={total_step}, episode={episode}\")\n",
    "    # except FileNotFoundError:\n",
    "    #     print(\"No previous model found. Starting training from scratch.\")\n",
    "\n",
    "    # def save_load_model(self, op, path=\"save\", fname=\"qnet.pt\"):\n",
    "    #     import os\n",
    "    #     if not os.path.exists(path):\n",
    "    #         os.makedirs(path)\n",
    "    #     file_path = os.path.join(path, fname)\n",
    "\n",
    "    #     if op == \"save\":\n",
    "    #         # 保存模型狀態、優化器狀態、學習步驟和經驗池計數\n",
    "    #         checkpoint = {\n",
    "    #             'qnet_eval_state_dict': self.qnet_eval.state_dict(),\n",
    "    #             'qnet_target_state_dict': self.qnet_target.state_dict(),\n",
    "    #             'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "    #             'learn_step_counter': self.learn_step_counter,\n",
    "    #             'memory_counter': self.memory_counter,\n",
    "    #         }\n",
    "    #         torch.save(checkpoint, file_path)\n",
    "\n",
    "    #     elif op == \"load\":\n",
    "    #         # 加載模型狀態、優化器狀態、學習步驟和經驗池計數\n",
    "    #         checkpoint = torch.load(file_path, map_location=self.device)\n",
    "    #         self.qnet_eval.load_state_dict(checkpoint['qnet_eval_state_dict'])\n",
    "    #         self.qnet_target.load_state_dict(checkpoint['qnet_target_state_dict'])\n",
    "    #         self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    #         self.learn_step_counter = checkpoint.get('learn_step_counter', -1)\n",
    "    #         self.memory_counter = checkpoint.get('memory_counter', -1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
