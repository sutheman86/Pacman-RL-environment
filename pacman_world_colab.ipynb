{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYYxhdROvEda"
      },
      "source": [
        "# Setup environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEEn8H1IvEdb"
      },
      "source": [
        "### mount google drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTVGFnZKvEdb"
      },
      "source": [
        "There are two ways to do it\n",
        "1. ***(recommended)*** :clone the repository https://github.com/sutheman86/Pacman-RL-environment, then upload the folder to your google drive to the correct location `My Drive/pacman_world`.\n",
        "    > I recommend it because you can change file as you want (like `Pacman_Complete`, `pacman_world.py`)\n",
        "2. Use shared folder (from me): https://drive.google.com/drive/folders/1AtbyLNNDesntlFNJ0HrVzW04ROS0HcyF?usp=drive_link create link to this folder at `My Drive/pacman_world`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QECDmNdvEdc",
        "outputId": "f60c2ffb-5270-40a1-d0ac-95b26f17b4fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3j48jj2vEdc"
      },
      "source": [
        "### Install required packages\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hww-vVSFvEdc"
      },
      "source": [
        "* After installing the package, colab will prompt you to **restart the runtime**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOYYUW2WvEdc"
      },
      "outputs": [],
      "source": [
        "!pip install babel copier Flask-Caching gym-notices gymnasium typing matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANiKFwxrvEdd"
      },
      "source": [
        "* Install gymnasium environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usaDmSRmvEde"
      },
      "outputs": [],
      "source": [
        "!pip install -e /content/drive/MyDrive/pacman_world/gymnasium\n",
        "!cp -r /content/drive/MyDrive/pacman_world/gymnasium/assets/ /content/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuGO_9Y5vEde"
      },
      "source": [
        "# Setup Pacman-world"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjKPISBDvEde"
      },
      "source": [
        "### 1. import all the required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XwCNJZxLvEde"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/pacman_world/gymnasium')\n",
        "import gymnasium_env\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import numpy as np\n",
        "import warnings\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhzPUOTbvEde"
      },
      "source": [
        "### 2. test pacman-world environment\n",
        "* Without wrapper, without DQN. Pacman will move randomly\n",
        "> ***Note: DO NOT set `render_mode='human'`, or the kernel will crash (if you run this Notebook locally)***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "HV2ZfD7RvEde",
        "outputId": "680cd196-4227-48a8-960b-6d7e681dd2d6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'warnings' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d40b0aac651e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDeprecationWarning\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0menv_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gymnasium_env/PacmanGymEnv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspeedup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrapped\u001b[0m \u001b[0;31m#減少限制\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'warnings' is not defined"
          ]
        }
      ],
      "source": [
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "env_name = \"gymnasium_env/PacmanGymEnv\"\n",
        "env = gym.make(env_name, speedup=5.0)\n",
        "env = env.unwrapped #減少限制\n",
        "\n",
        "print(\"environment:\", env_name)\n",
        "print(\"action space:\", env.action_space.n)\n",
        "# print(\"action:\", env.unwrapped.get_action_meanings())\n",
        "print(\"observation space:\", env.observation_space.shape)\n",
        "\n",
        "state = env.reset()\n",
        "step = 0\n",
        "total_reward=0\n",
        "while True:\n",
        "    action = env.action_space.sample()\n",
        "    obs, reward, terminated, info = env.step(action)\n",
        "    step+=1\n",
        "    total_reward += reward\n",
        "    print('\\rStep: {:3d} | Reward: {:.3f} / {:.3f} | Action: {:.3f} | Info: {}'.format(step, reward, total_reward, action, info), end=\"\")\n",
        "    # if step%30==0:\n",
        "    #     plt.figure()\n",
        "    #     plt.imshow(obs)\n",
        "    #     plt.axis('off')  # 关闭坐标轴\n",
        "    # print(f\"state: {state[1]}\")\n",
        "    if terminated:\n",
        "        break\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJsIPwupvEdf"
      },
      "source": [
        "### 3. Define Wrapper\n",
        "* `PacmanEnvWrapper` will contain important information for DQN to use"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76ZqEeTKvEdf"
      },
      "outputs": [],
      "source": [
        "\n",
        "class PacmanEnvWrapper(gym.Wrapper):\n",
        "    def __init__(self, env, k, img_size=(84,84)):\n",
        "        gym.Wrapper.__init__(self, env)\n",
        "        self.k = k\n",
        "        self.env = gym.make(env_name, speedup=4.0)\n",
        "        self.img_size = img_size\n",
        "        obs_shape = env.observation_space.shape\n",
        "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(k, img_size[0], img_size[1]), dtype=np.float32)\n",
        "\n",
        "    def _preprocess(self, state, th=0.182):\n",
        "        # TODO(Lab-1): Image processing.\n",
        "        state = np.array(Image.fromarray(state).resize(self.img_size,Image.BILINEAR))\n",
        "        state = state.astype(np.float32).mean(2) / 255.\n",
        "        state[state > th] = 1.0\n",
        "        state[state <= th] = 0.0\n",
        "\n",
        "        return state\n",
        "\n",
        "    def reset(self):\n",
        "        state = self.env.reset()\n",
        "\n",
        "        # 確認是否返回了tuple，並提取圖像\n",
        "        if isinstance(state, tuple):\n",
        "            state = state[0]\n",
        "\n",
        "        state = self._preprocess(state)\n",
        "        state = state[np.newaxis, ...].repeat(self.k, axis=0)  # 堆疊多幀\n",
        "        return state\n",
        "\n",
        "\n",
        "    def step(self, action):\n",
        "        state_next = []\n",
        "        info =[]\n",
        "        reward = 0\n",
        "        terminated = False\n",
        "\n",
        "        for i in range(self.k):\n",
        "            if not terminated:\n",
        "                state_next_f, reward_f, terminated_f, info_f = self.env.step(action)\n",
        "                state_next_f = self._preprocess(state_next_f)\n",
        "                reward += reward_f\n",
        "                terminated = terminated_f\n",
        "                info.append(info_f)\n",
        "            state_next.append(state_next_f[np.newaxis, ...])\n",
        "        state_next = np.concatenate(state_next, 0)\n",
        "        return state_next, reward, terminated, info\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPm-ty_hvEdf"
      },
      "source": [
        "* Initialize Wrapper and test it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XQwTkxv6vEdf"
      },
      "outputs": [],
      "source": [
        "# Test Code\n",
        "env_pacman = PacmanEnvWrapper(env, k=4, img_size=(84,84))\n",
        "print(\"observation space:\", env_pacman.observation_space.shape)\n",
        "\n",
        "state = env_pacman.reset()\n",
        "action = env_pacman.action_space.sample()\n",
        "obs, reward, terminated, info = env_pacman.step(action)\n",
        "print(obs)\n",
        "plt.imshow(obs[0], cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yuValVMvEdg"
      },
      "source": [
        "### 3.5 Test `PacmanEnvWrapper`\n",
        "* Without DQN, test if it works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N1vsNYrbvEdg"
      },
      "outputs": [],
      "source": [
        "\n",
        "# env_name = \"gymnasium_env/PacmanGymEnv\"\n",
        "# env = gym.make(env_name, speedup=4.0)\n",
        "# env = env.unwrapped #減少限制\n",
        "\n",
        "# print(\"environment:\", env_name)\n",
        "# print(\"action space:\", env.action_space.n)\n",
        "# print(\"action:\", env.unwrapped.get_action_meanings())\n",
        "# print(\"observation space:\", env.observation_space.shape)\n",
        "pacman_env = PacmanEnvWrapper(env, k=4, img_size=(84,84))\n",
        "state = pacman_env.reset()\n",
        "step = 0\n",
        "total_reward = 0\n",
        "while True:\n",
        "    action = pacman_env.action_space.sample()\n",
        "    obs, reward, terminated, info = pacman_env.step(action)\n",
        "    step+=1\n",
        "    total_reward += reward\n",
        "    print('\\rStep: {:3d} | Reward: {:.3f} / {:.3f} | Action: {:.3f} | Info: {}'.format(step, reward, total_reward, action, info), end=\"\")\n",
        "\n",
        "    # if step%40==0:\n",
        "    #     # print(30)\n",
        "    #     plt.figure()\n",
        "    #     plt.imshow(obs[0],cmap=\"gray\")\n",
        "    #     plt.axis('off')  # 关闭坐标轴\n",
        "    # print(f\"state: {state[1]}\")\n",
        "    if terminated:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8LH6-eGvEdg"
      },
      "source": [
        "### 4. Output to GIF\n",
        "* remember to run it, it'll be used later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDNniRYUvEdg"
      },
      "outputs": [],
      "source": [
        "project_root = os.getcwd()\n",
        "def save_gif(img_buffer, fname, gif_path=os.path.join(project_root, \"GIF\")):\n",
        "    if not os.path.exists(gif_path):\n",
        "        os.makedirs(gif_path)\n",
        "    img_buffer[0].save(os.path.join(gif_path, fname), save_all=True, append_images=img_buffer[1:], duration=3, loop=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGW6n_NJvEdg"
      },
      "source": [
        "# Implement DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayPRmu3CvEdg"
      },
      "source": [
        "### 5.1 Define QNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0XGeyGCAvEdg"
      },
      "outputs": [],
      "source": [
        "\n",
        "class QNet(nn.Module):\n",
        "    # TODO(Lab-4): Q-Network architecture.\n",
        "    def __init__(self, input_shape, n_actions):\n",
        "        super(QNet, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(input_shape[0], 32, kernel_size=8, stride=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        conv_out_size = self._get_conv_out(input_shape)\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(conv_out_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, n_actions),\n",
        "        )\n",
        "\n",
        "    def _get_conv_out(self, shape):\n",
        "        o = self.conv(torch.zeros(1, *shape))\n",
        "        return int(np.prod(o.size()))\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv_out = self.conv(x)\n",
        "        out = self.fc(conv_out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6kGBuu-vEdg"
      },
      "source": [
        "### 5.2 Define DQN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qbfHS-dQvEdh"
      },
      "outputs": [],
      "source": [
        "class DeepQNetwork():\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_actions,\n",
        "        input_shape,\n",
        "        qnet,\n",
        "        device,\n",
        "        learning_rate=2e-4,\n",
        "        reward_decay=0.99,\n",
        "        replace_target_iter=1000,\n",
        "        memory_size=10000,\n",
        "        batch_size=32,\n",
        "    ):\n",
        "        # initialize parameters\n",
        "        self.n_actions = n_actions\n",
        "        self.input_shape = input_shape\n",
        "        self.lr = learning_rate\n",
        "        self.gamma = reward_decay\n",
        "        self.replace_target_iter = replace_target_iter\n",
        "        self.memory_size = memory_size\n",
        "        self.batch_size = batch_size\n",
        "        self.device = device\n",
        "        self.learn_step_counter = 0\n",
        "        self.init_memory()\n",
        "\n",
        "        # Network\n",
        "        self.qnet_eval = qnet(self.input_shape, self.n_actions).to(self.device)\n",
        "        self.qnet_target = qnet(self.input_shape, self.n_actions).to(self.device)\n",
        "        self.qnet_target.eval()\n",
        "        self.optimizer = optim.RMSprop(self.qnet_eval.parameters(), lr=self.lr)\n",
        "\n",
        "    def choose_action(self, state, epsilon=0):\n",
        "        # 將狀態轉換為 FloatTensor 並增加 batch 維度\n",
        "        state = torch.FloatTensor(state).unsqueeze(0).to(self.device)\n",
        "        actions_value = self.qnet_eval.forward(state)\n",
        "        if np.random.uniform() > epsilon:  # greedy\n",
        "            action = torch.max(actions_value, 1)[1].data.cpu().numpy()[0]\n",
        "        else:  # random\n",
        "            action = np.random.randint(0, self.n_actions)\n",
        "        return action\n",
        "\n",
        "    def learn(self):\n",
        "        # 替换目标网络参数\n",
        "        if self.learn_step_counter % self.replace_target_iter == 0:\n",
        "            self.qnet_target.load_state_dict(self.qnet_eval.state_dict())\n",
        "\n",
        "        # 随机采样经验池中的一个批次\n",
        "        if self.memory_counter > self.memory_size:\n",
        "            sample_index = np.random.choice(self.memory_size, size=self.batch_size)\n",
        "        else:\n",
        "            sample_index = np.random.choice(self.memory_counter, size=self.batch_size)\n",
        "\n",
        "        b_s = torch.FloatTensor(self.memory[\"s\"][sample_index]).to(self.device)\n",
        "        b_a = torch.LongTensor(self.memory[\"a\"][sample_index]).to(self.device)\n",
        "        b_r = torch.FloatTensor(self.memory[\"r\"][sample_index]).to(self.device)\n",
        "        b_s_ = torch.FloatTensor(self.memory[\"s_\"][sample_index]).to(self.device)\n",
        "        b_d = torch.FloatTensor(self.memory[\"done\"][sample_index]).to(self.device)\n",
        "\n",
        "        # DQN 和 DDQN 两种方式\n",
        "        q_curr_eval = self.qnet_eval(b_s).gather(1, b_a)\n",
        "        q_next_target = self.qnet_target(b_s_).detach()\n",
        "        q_next_eval = self.qnet_eval(b_s_).detach()\n",
        "        next_state_values = q_next_target.gather(1, q_next_eval.max(1)[1].unsqueeze(1))  # DDQN\n",
        "        q_curr_recur = b_r + (1 - b_d) * self.gamma * next_state_values\n",
        "\n",
        "        # 损失计算\n",
        "        self.loss = F.smooth_l1_loss(q_curr_eval, q_curr_recur)\n",
        "\n",
        "        # 反向传播和优化\n",
        "        self.optimizer.zero_grad()\n",
        "        self.loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.learn_step_counter += 1\n",
        "\n",
        "        return self.loss.detach().cpu().numpy()\n",
        "\n",
        "\n",
        "\n",
        "    def init_memory(self):\n",
        "        # 初始化经验池\n",
        "        self.memory = {\n",
        "            \"s\": np.zeros((self.memory_size, *self.input_shape)),\n",
        "            \"a\": np.zeros((self.memory_size, 1)),\n",
        "            \"r\": np.zeros((self.memory_size, 1)),\n",
        "            \"s_\": np.zeros((self.memory_size, *self.input_shape)),\n",
        "            \"done\": np.zeros((self.memory_size, 1)),\n",
        "        }\n",
        "\n",
        "    def store_transition(self, s, a, r, s_, d):\n",
        "        if not hasattr(self, 'memory_counter'):\n",
        "            self.memory_counter = 0\n",
        "        index = self.memory_counter % self.memory_size\n",
        "        self.memory[\"s\"][index] = s\n",
        "        self.memory[\"a\"][index] = np.array(a).reshape(-1, 1)\n",
        "        self.memory[\"r\"][index] = np.array(r).reshape(-1, 1)\n",
        "        self.memory[\"s_\"][index] = s_\n",
        "        self.memory[\"done\"][index] = np.array(d).reshape(-1, 1)\n",
        "        self.memory_counter += 1\n",
        "\n",
        "    def save_load_model(self, op, path=\"save\", fname=\"qnet.pt\"):\n",
        "        if not os.path.exists(path):\n",
        "            os.makedirs(path)\n",
        "        file_path = os.path.join(path, fname)\n",
        "\n",
        "        if op == \"save\":\n",
        "            # 保存模型狀態、優化器狀態、學習步驟和經驗池計數\n",
        "            checkpoint = {\n",
        "                'qnet_eval_state_dict': self.qnet_eval.state_dict(),\n",
        "                'qnet_target_state_dict': self.qnet_target.state_dict(),\n",
        "                'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                'learn_step_counter': self.learn_step_counter,\n",
        "                'memory_counter': self.memory_counter,\n",
        "            }\n",
        "            torch.save(checkpoint, file_path)\n",
        "            print(f\"Model saved successfully at {file_path}\")\n",
        "\n",
        "        elif op == \"load\":\n",
        "            try:\n",
        "                # 加載模型狀態、優化器狀態、學習步驟和經驗池計數\n",
        "                checkpoint = torch.load(file_path, map_location=self.device)\n",
        "\n",
        "                # 檢查是否包含所有必需的鍵\n",
        "                required_keys = ['qnet_eval_state_dict', 'qnet_target_state_dict', 'optimizer_state_dict']\n",
        "                missing_keys = [key for key in required_keys if key not in checkpoint]\n",
        "\n",
        "                if missing_keys:\n",
        "                    raise KeyError(f\"Missing keys in checkpoint: {missing_keys}\")\n",
        "\n",
        "                # 加載各部分的狀態\n",
        "                self.qnet_eval.load_state_dict(checkpoint['qnet_eval_state_dict'])\n",
        "                self.qnet_target.load_state_dict(checkpoint['qnet_target_state_dict'])\n",
        "                self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "                # 選擇性地加載學習計數\n",
        "                self.learn_step_counter = checkpoint.get('learn_step_counter', 0)\n",
        "                self.memory_counter = checkpoint.get('memory_counter', 0)\n",
        "\n",
        "                print(\"Model loaded successfully from\", file_path)\n",
        "\n",
        "            except FileNotFoundError:\n",
        "                print(f\"No saved model found at {file_path}, starting fresh.\")\n",
        "            except KeyError as e:\n",
        "                print(f\"Error loading model: {e}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sqeQSnGvEdh"
      },
      "source": [
        "### 5.3 Define Epsilon Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kz1i8hg2vEdh"
      },
      "outputs": [],
      "source": [
        "def epsilon_compute(frame_id, epsilon_max=1, epsilon_min=0.05, epsilon_decay=100000):\n",
        "    return epsilon_min + (epsilon_max - epsilon_min) * np.exp(-frame_id / epsilon_decay)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAxCHKnnvEdh"
      },
      "source": [
        "* Graph of epsilon(0) to epsilon(400000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KkDkVE7OvEdh",
        "outputId": "68a8702c-0c0b-48aa-e35c-d25b7a8655fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x76d66aaf3850>]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error in callback <function _draw_all_if_interactive at 0x76d787f48e50> (for post_execute), with arguments args (),kwargs {}:\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "object __array__ method not producing an array",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/matplotlib/pyplot.py:268\u001b[0m, in \u001b[0;36m_draw_all_if_interactive\u001b[0;34m()\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_draw_all_if_interactive\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m matplotlib\u001b[38;5;241m.\u001b[39mis_interactive():\n\u001b[0;32m--> 268\u001b[0m         \u001b[43mdraw_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/matplotlib/_pylab_helpers.py:131\u001b[0m, in \u001b[0;36mGcf.draw_all\u001b[0;34m(cls, force)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force \u001b[38;5;129;01mor\u001b[39;00m manager\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mstale:\n\u001b[0;32m--> 131\u001b[0m         \u001b[43mmanager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/matplotlib/backend_bases.py:1905\u001b[0m, in \u001b[0;36mFigureCanvasBase.draw_idle\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1903\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_idle_drawing:\n\u001b[1;32m   1904\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_idle_draw_cntx():\n\u001b[0;32m-> 1905\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:387\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\u001b[38;5;241m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\n\u001b[1;32m    386\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdraw()\n",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/matplotlib/artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[1;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/matplotlib/figure.py:3161\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3158\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   3159\u001b[0m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m-> 3161\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3162\u001b[0m mimage\u001b[38;5;241m.\u001b[39m_draw_list_compositing_images(\n\u001b[1;32m   3163\u001b[0m     renderer, \u001b[38;5;28mself\u001b[39m, artists, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppressComposite)\n\u001b[1;32m   3165\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/matplotlib/patches.py:632\u001b[0m, in \u001b[0;36mPatch.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    630\u001b[0m tpath \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform_path_non_affine(path)\n\u001b[1;32m    631\u001b[0m affine \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mget_affine()\n\u001b[0;32m--> 632\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_paths_with_artist_properties\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maffine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Work around a bug in the PDF and SVG renderers, which\u001b[39;49;00m\n\u001b[1;32m    636\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# do not draw the hatches if the facecolor is fully\u001b[39;49;00m\n\u001b[1;32m    637\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# transparent, but do if it is None.\u001b[39;49;00m\n\u001b[1;32m    638\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_facecolor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_facecolor\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/matplotlib/patches.py:617\u001b[0m, in \u001b[0;36mPatch._draw_paths_with_artist_properties\u001b[0;34m(self, renderer, draw_path_args_list)\u001b[0m\n\u001b[1;32m    614\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m PathEffectRenderer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_path_effects(), renderer)\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m draw_path_args \u001b[38;5;129;01min\u001b[39;00m draw_path_args_list:\n\u001b[0;32m--> 617\u001b[0m     \u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdraw_path_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    619\u001b[0m gc\u001b[38;5;241m.\u001b[39mrestore()\n\u001b[1;32m    620\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:131\u001b[0m, in \u001b[0;36mRendererAgg.draw_path\u001b[0;34m(self, gc, path, transform, rgbFace)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_renderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrgbFace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOverflowError\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m         cant_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
            "\u001b[0;31mValueError\u001b[0m: object __array__ method not producing an array"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "object __array__ method not producing an array",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/IPython/core/formatters.py:343\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[1;32m    345\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/IPython/core/pylabtools.py:170\u001b[0m, in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[1;32m    168\u001b[0m     FigureCanvasBase(fig)\n\u001b[0;32m--> 170\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    171\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/matplotlib/backend_bases.py:2204\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2201\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2202\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2203\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[0;32m-> 2204\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2205\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2206\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2207\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2208\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2209\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2210\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2211\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2212\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/matplotlib/backend_bases.py:2054\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[1;32m   2051\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2052\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   2053\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[0;32m-> 2054\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2056\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[1;32m   2057\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:496\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    450\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 496\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:444\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_print_pil\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, fmt, pil_kwargs, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    440\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m    Draw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03m    *pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 444\u001b[0m     \u001b[43mFigureCanvasAgg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    445\u001b[0m     mpl\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave(\n\u001b[1;32m    446\u001b[0m         filename_or_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_rgba(), \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mfmt, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    447\u001b[0m         dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi, metadata\u001b[38;5;241m=\u001b[39mmetadata, pil_kwargs\u001b[38;5;241m=\u001b[39mpil_kwargs)\n",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:387\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\u001b[38;5;241m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\n\u001b[1;32m    386\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdraw()\n",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/matplotlib/artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[1;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/matplotlib/figure.py:3161\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3158\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   3159\u001b[0m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m-> 3161\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3162\u001b[0m mimage\u001b[38;5;241m.\u001b[39m_draw_list_compositing_images(\n\u001b[1;32m   3163\u001b[0m     renderer, \u001b[38;5;28mself\u001b[39m, artists, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppressComposite)\n\u001b[1;32m   3165\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/matplotlib/patches.py:632\u001b[0m, in \u001b[0;36mPatch.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    630\u001b[0m tpath \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform_path_non_affine(path)\n\u001b[1;32m    631\u001b[0m affine \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mget_affine()\n\u001b[0;32m--> 632\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_paths_with_artist_properties\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maffine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    635\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Work around a bug in the PDF and SVG renderers, which\u001b[39;49;00m\n\u001b[1;32m    636\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# do not draw the hatches if the facecolor is fully\u001b[39;49;00m\n\u001b[1;32m    637\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# transparent, but do if it is None.\u001b[39;49;00m\n\u001b[1;32m    638\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_facecolor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_facecolor\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/matplotlib/patches.py:617\u001b[0m, in \u001b[0;36mPatch._draw_paths_with_artist_properties\u001b[0;34m(self, renderer, draw_path_args_list)\u001b[0m\n\u001b[1;32m    614\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m PathEffectRenderer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_path_effects(), renderer)\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m draw_path_args \u001b[38;5;129;01min\u001b[39;00m draw_path_args_list:\n\u001b[0;32m--> 617\u001b[0m     \u001b[43mrenderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdraw_path_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    619\u001b[0m gc\u001b[38;5;241m.\u001b[39mrestore()\n\u001b[1;32m    620\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpatch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m~/.conda/envs/pacman-RL-environment/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:131\u001b[0m, in \u001b[0;36mRendererAgg.draw_path\u001b[0;34m(self, gc, path, transform, rgbFace)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_renderer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrgbFace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOverflowError\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m         cant_chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
            "\u001b[0;31mValueError\u001b[0m: object __array__ method not producing an array"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Test Code\n",
        "frame_ids = np.array(range(400000))\n",
        "epsilons = epsilon_compute(frame_ids)\n",
        "plt.plot(epsilons)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCmJgt9QvEdi"
      },
      "source": [
        "### 6. Initialize DQN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R61QnJlivEdi",
        "outputId": "b807745c-24ca-4b1c-b331-8b6b63b9d432"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "QNet(\n",
            "  (conv): Sequential(\n",
            "    (0): Conv2d(4, 32, kernel_size=(8, 8), stride=(4, 4))\n",
            "    (1): ReLU()\n",
            "    (2): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2))\n",
            "    (3): ReLU()\n",
            "    (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (5): ReLU()\n",
            "  )\n",
            "  (fc): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=3136, out_features=512, bias=True)\n",
            "    (2): ReLU()\n",
            "    (3): Linear(in_features=512, out_features=5, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "stack_frames = 4\n",
        "img_size = (84,84)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "agent = DeepQNetwork(\n",
        "        n_actions = env.action_space.n,\n",
        "        input_shape = [stack_frames, *img_size],\n",
        "        qnet = QNet,\n",
        "        device = device,\n",
        "        learning_rate = 2e-4,\n",
        "        reward_decay = 0.99,\n",
        "        replace_target_iter = 1000,\n",
        "        memory_size = 10000,\n",
        "        batch_size = 1024,)\n",
        "\n",
        "print(agent.qnet_eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UsmiHSPvEdi"
      },
      "source": [
        "### 7. Define `Play()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLp5Y_PvvEdi"
      },
      "outputs": [],
      "source": [
        "\n",
        "import gymnasium as gym\n",
        "import gymnasium_env\n",
        "def play(env, agent, stack_frames, img_size):\n",
        "    # Reset environment.\n",
        "    state = env.reset()\n",
        "    img_buffer = [Image.fromarray(state[0]*255)]\n",
        "\n",
        "    # Initialize information.\n",
        "    step = 0\n",
        "    total_reward = 0\n",
        "\n",
        "    # One episode.\n",
        "    while True:\n",
        "        # Select action.\n",
        "        action = agent.choose_action(state, 1)\n",
        "\n",
        "        # Get next stacked state.\n",
        "        state_next, reward, done, info = env.step(action)\n",
        "        if step % 2 == 0:\n",
        "            img_buffer.append(Image.fromarray(state_next[0]*255))\n",
        "\n",
        "        state = state_next.copy()\n",
        "        step += 1\n",
        "        total_reward += reward\n",
        "        print('\\rStep: {:3d} | Reward: {:.3f} / {:.3f} | Action: {:.3f} | Info: {}'.format(step, reward, total_reward, action, info[0]), end=\"\")\n",
        "\n",
        "        if done or step>200:\n",
        "            print()\n",
        "            break\n",
        "\n",
        "    return img_buffer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qwf7_m3mvEdi"
      },
      "source": [
        "### 8. Test play"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyTu4o6LvEdi",
        "outputId": "fb0f90c1-2bd6-449f-f45a-9603a38186b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Step:  61 | Reward: -70.000 / 52.000 | Action: 1.000 | Info: {'lives': 1, 'total_score': 180}\n"
          ]
        }
      ],
      "source": [
        "env_pacman = PacmanEnvWrapper(env, k=4, img_size=(84,84))\n",
        "img_buffer = play(env_pacman, agent, stack_frames, img_size)\n",
        "save_gif(img_buffer, fname=\"test.gif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZNzHiZdvEdi"
      },
      "source": [
        "# Start Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3B9GMcAvEdi"
      },
      "source": [
        "### 9. Define `train()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUaGc5FEvEdj"
      },
      "outputs": [],
      "source": [
        "def train(env, agent, stack_frames, img_size, save_path=\"save\", max_steps=1000000):\n",
        "    total_step = 0\n",
        "    episode = 0\n",
        "\n",
        "    while total_step <= max_steps:\n",
        "        # Reset environment.\n",
        "        state = env.reset()\n",
        "\n",
        "        # 如果 state 是 tuple，提取圖像\n",
        "        if isinstance(state, tuple):\n",
        "            state = state[0]\n",
        "\n",
        "        # Initialize information.\n",
        "        step = 0\n",
        "        total_reward = 0\n",
        "        loss = 0\n",
        "\n",
        "        # One episode.\n",
        "        while True:\n",
        "            # TODO(Lab-6): Select action.\n",
        "            epsilon = epsilon_compute(total_step)\n",
        "            action = agent.choose_action(state, epsilon)\n",
        "\n",
        "            # Get next observation.\n",
        "            obs, reward, terminated, info = env.step(action)\n",
        "\n",
        "            # 如果 obs 是 tuple，提取圖像\n",
        "            if isinstance(obs, tuple):\n",
        "                obs = obs[0]\n",
        "\n",
        "            # 判斷是否遊戲結束\n",
        "            done = terminated\n",
        "\n",
        "            # TODO(Lab-7): Train RL model.\n",
        "            # Store transition and learn.\n",
        "            agent.store_transition(state, action, reward, obs, done)\n",
        "            if total_step > 4 * agent.batch_size:\n",
        "                loss = agent.learn()\n",
        "\n",
        "            state = obs.copy()  # 更新狀態\n",
        "            step += 1\n",
        "            total_step += 1\n",
        "            total_reward += reward\n",
        "\n",
        "            # 確保 loss 為浮點數以便於打印\n",
        "            if total_step % 2 == 0 or done:\n",
        "                print('\\rEpisode: {:3d} | Step: {:3d} / {:3d} | Reward: {:.3f} / {:.3f} | Loss: {:.3f} | Epsilon: {:.3f}'\\\n",
        "                    .format(episode, step, total_step, reward, total_reward, loss, epsilon), end=\"\")\n",
        "\n",
        "            if total_step % 1000 == 0:\n",
        "                print(\"\\nSave Model ...\")\n",
        "                agent.save_load_model(\n",
        "                    op=\"save\",\n",
        "                    path=save_path,\n",
        "                    fname=\"qnet.pt\"\n",
        "                )\n",
        "                print(\"Generate GIF ...\")\n",
        "                img_buffer = play(env, agent, stack_frames, img_size)\n",
        "                save_gif(img_buffer, \"train_\" + str(total_step).zfill(6) + \".gif\")\n",
        "                print(\"Done !!\")\n",
        "\n",
        "            if done or step > 2000:\n",
        "                episode += 1\n",
        "                print()\n",
        "                break\n",
        "\n",
        "        if total_step > max_steps:\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhv2JIpMvEdj"
      },
      "source": [
        "### 10. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RK1qir7WvEdj"
      },
      "outputs": [],
      "source": [
        "env_pacman = PacmanEnvWrapper(env, k=4, img_size=(84,84))\n",
        "train(env_pacman, agent, stack_frames, img_size, save_path=os.path.join(project_root, \"save\"), max_steps=600000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyUGtCYDvEdj"
      },
      "source": [
        "# Evaluate Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qsix9QEjvEdj"
      },
      "source": [
        "<h1><i><b>MAKE SURE TO DOWNLOAD YOUR TRAINED MODEL!!!</h1></i></b>\n",
        "because colab will clear all files after runtime shutdown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3UpTbBtvEdj"
      },
      "outputs": [],
      "source": [
        "agent.save_load_model(op=\"load\", path=os.path.join(project_root, \"save\"), fname=\"qnet.pt\")\n",
        "env_pacman = PacmanEnvWrapper(env, k=4, img_size=(84,84))\n",
        "img_buffer = play(env_pacman, agent, stack_frames, img_size)\n",
        "save_gif(img_buffer, \"eval.gif\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMWhTkEnvEdj"
      },
      "source": [
        "# Old Codes\n",
        "* Would probably be useful later or really just junks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqkTEz9JvEdk"
      },
      "source": [
        "### Step 1.\n",
        "* This is to test `PacmanGymEnv` could run by itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLCQrs3pvEdk"
      },
      "outputs": [],
      "source": [
        "\n",
        "# import gymnasium_env\n",
        "# import gymnasium\n",
        "# import warnings\n",
        "# from PIL import Image\n",
        "# import numpy as np\n",
        "# import os\n",
        "\n",
        "# # 設定無視窗模式\n",
        "# os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
        "\n",
        "# # 忽略 DeprecationWarning\n",
        "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# # 初始化環境\n",
        "# env = gymnasium.make('gymnasium_env/PacmanGymEnv', speedup=4.0)\n",
        "# obs, info = env.reset()\n",
        "# env_unwrapped = env.unwrapped\n",
        "\n",
        "# # 用來保存每一幀的圖像\n",
        "# frames = []\n",
        "\n",
        "# # 設定最多 1000 步\n",
        "# for step in range(1000):\n",
        "#     action = env.action_space.sample()  # 隨機取樣一個動作\n",
        "#     obs, reward, done, info = env.step(action)\n",
        "\n",
        "\n",
        "#     # 確保返回值非空並且是 numpy array 格式\n",
        "#     if obs is not None and isinstance(obs, np.ndarray):\n",
        "#         img = Image.fromarray(obs)  # 轉換為 PIL 圖像格式\n",
        "#         frames.append(img)  # 添加幀到 frames 列表中\n",
        "#     else:\n",
        "#         print(\"Render did not return a valid image.\")\n",
        "\n",
        "#     print(f\"Step: {step + 1}, Action: {action}, Reward: {reward}, Info: {info}, Done: {done}\")\n",
        "\n",
        "#     # 檢查是否回合結束\n",
        "#     if done:\n",
        "#         print(\"Episode finished!\")\n",
        "#         break\n",
        "\n",
        "# # 關閉環境\n",
        "# env.close()\n",
        "\n",
        "# # 保存為 GIF\n",
        "# output_path = \"../GIF/pacman_game.gif\"\n",
        "# frames[0].save(output_path, save_all=True, append_images=frames[1:], duration=100, loop=1)\n",
        "# print(f\"GIF saved as {output_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwRk1vVsvEdk"
      },
      "source": [
        "### Step 5.\n",
        "* Old implementation of `play()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFsqH9dyvEdk"
      },
      "outputs": [],
      "source": [
        "# def play(env, agent, stack_frames, img_size):\n",
        "#     #os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
        "#     # Reset environment.\n",
        "#     state = env.reset()\n",
        "\n",
        "#     # 如果state是tuple，提取第一個元素作為圖像\n",
        "#     if isinstance(state, tuple):\n",
        "#         state = state[0]\n",
        "\n",
        "#     # state形狀應該是 (k, 84, 84)，所以不再提取單幀\n",
        "#     # 確保數據類型為uint8，並去除不必要的維度\n",
        "#     state = (state * 255).astype(np.uint8)\n",
        "\n",
        "#     # 初始化圖像緩衝區\n",
        "#     img_buffer = [Image.fromarray(state[0])]  # 顯示第一幀\n",
        "\n",
        "#     # Initialize information.\n",
        "#     step = 0\n",
        "#     total_reward = 0\n",
        "\n",
        "#     # One episode.\n",
        "#     while True:\n",
        "#         # Select action.\n",
        "#         action = agent.choose_action(state, 0)\n",
        "\n",
        "#         # Get next stacked state.\n",
        "#         state_next, reward, terminated, info = env.step(action)\n",
        "\n",
        "#         # 如果 state_next 是 tuple，提取圖像\n",
        "#         if isinstance(state_next, tuple):\n",
        "#             state_next = state_next[0]\n",
        "\n",
        "#         # 不再提取單幀，直接使用多幀數據\n",
        "#         state_next = (state_next * 255).astype(np.uint8)\n",
        "\n",
        "#         # 每兩步存儲一幀圖像\n",
        "#         if step % 2 == 0:\n",
        "#             img_buffer.append(Image.fromarray(state_next[0]))  # 顯示第一幀\n",
        "\n",
        "#         state = state_next.copy()  # 更新狀態\n",
        "#         step += 1\n",
        "#         total_reward += reward\n",
        "#         print('\\rStep: {:3d} | Reward: {:.3f} / {:.3f} | Action: {:.3f} | Info: {}'.format(step, reward, total_reward, action, info[0]), end=\"\")\n",
        "\n",
        "\n",
        "#         # 檢查遊戲是否結束或步數超過2000\n",
        "#         if terminated  or step > 400:\n",
        "#             print()\n",
        "#             break\n",
        "\n",
        "#     return img_buffer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq88mOFFvEdk"
      },
      "source": [
        "### Step 5.2\n",
        "* Old implementation of learn()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLiOyNbZvEdk"
      },
      "source": [
        "### Step 9.\n",
        "* This piece of code attempted to load model but failed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONXacdbbvEdk"
      },
      "outputs": [],
      "source": [
        "    # 嘗試加載模型和訓練狀態\n",
        "    # try:\n",
        "    #     print(\"Loading model and training status...\")\n",
        "    #     status = agent.save_load_model(op=\"load\", path=save_path, fname=\"qnet.pt\")\n",
        "    #     total_step = status[\"learn_step_counter\"]\n",
        "    #     episode = status[\"memory_counter\"]\n",
        "    #     print(f\"Resuming training from total_step={total_step}, episode={episode}\")\n",
        "    # except FileNotFoundError:\n",
        "    #     print(\"No previous model found. Starting training from scratch.\")\n",
        "    # except KeyError as e:\n",
        "    #     print(f\"Missing key in checkpoint: {e}\")\n",
        "\n",
        "    # try:\n",
        "    #     print(\"Loading model and training status...\")\n",
        "    #     status = agent.save_load_model(op=\"load\", path=save_path, fname=\"qnet.pt\")\n",
        "    #     total_step = status.get(\"total_step\", 0)\n",
        "    #     episode = status.get(\"episode\", 0)\n",
        "    #     print(f\"Resuming training from total_step={total_step}, episode={episode}\")\n",
        "    # except FileNotFoundError:\n",
        "    #     print(\"No previous model found. Starting training from scratch.\")\n",
        "\n",
        "    # def save_load_model(self, op, path=\"save\", fname=\"qnet.pt\"):\n",
        "    #     import os\n",
        "    #     if not os.path.exists(path):\n",
        "    #         os.makedirs(path)\n",
        "    #     file_path = os.path.join(path, fname)\n",
        "\n",
        "    #     if op == \"save\":\n",
        "    #         # 保存模型狀態、優化器狀態、學習步驟和經驗池計數\n",
        "    #         checkpoint = {\n",
        "    #             'qnet_eval_state_dict': self.qnet_eval.state_dict(),\n",
        "    #             'qnet_target_state_dict': self.qnet_target.state_dict(),\n",
        "    #             'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "    #             'learn_step_counter': self.learn_step_counter,\n",
        "    #             'memory_counter': self.memory_counter,\n",
        "    #         }\n",
        "    #         torch.save(checkpoint, file_path)\n",
        "\n",
        "    #     elif op == \"load\":\n",
        "    #         # 加載模型狀態、優化器狀態、學習步驟和經驗池計數\n",
        "    #         checkpoint = torch.load(file_path, map_location=self.device)\n",
        "    #         self.qnet_eval.load_state_dict(checkpoint['qnet_eval_state_dict'])\n",
        "    #         self.qnet_target.load_state_dict(checkpoint['qnet_target_state_dict'])\n",
        "    #         self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    #         self.learn_step_counter = checkpoint.get('learn_step_counter', 0)\n",
        "    #         self.memory_counter = checkpoint.get('memory_counter', 0)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "pacman-RL-environment",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}